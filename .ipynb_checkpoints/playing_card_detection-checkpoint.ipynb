{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hV3zwf_Aa0Ug"
   },
   "source": [
    "Playing Card Detection using YOLOv5\n",
    "\n",
    "Trained on 600+ images using 500 + 106 train and validation split\n",
    "\n",
    "For training used yolov5 <b>custom object detection</b><br>\n",
    "<a href= \"https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\">Link</a> <br>\n",
    "The model are exported in <b>Onnx</b> format to infere in opencv dnn\n",
    "\n",
    "Card detection and Number/card recoginition are different models\n",
    "\n",
    "Also images are annotated by hand and some are <b>computer generated</b> image + annotation with different background, will attach link for dataset and scripts\n",
    "\n",
    "For inferencing Used <b>cv2 dnn</b>  module, we can use openvino or tensorrt for speed boost\n",
    "\n",
    "Code below infere one image of card and no.s on it, we can make changes for video inferenceing and webcam as well\n",
    "\n",
    "Model accuracy is not good enough since <b>data is limited</b> \n",
    "so classes are switching.\n",
    "If I get more data will update models with better accuracy\n",
    "\n",
    "Dataset and dataset creating scripts added in drive,can check it here,also added models if you want to test\n",
    "https://drive.google.com/drive/folders/1TvaS_z3gIUGeUkZXhE3CmMQmAM2ZZtAH?usp=sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "N62jV9vDEX2t"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6-efSDpAFGte"
   },
   "outputs": [],
   "source": [
    "INPUT_WIDTH = 640\n",
    "INPUT_HEIGHT = 640\n",
    "SCORE_THRESHOLD = 0.5\n",
    "NMS_THRESHOLD = 0.45\n",
    "CONFIDENCE_THRESHOLD = 0.45\n",
    "\n",
    "# Text parameters.\n",
    "FONT_FACE = cv2.FONT_HERSHEY_SIMPLEX\n",
    "FONT_SCALE = 0.7\n",
    "THICKNESS = 1\n",
    "\n",
    "# Colors.\n",
    "BLACK  = (0,0,0)\n",
    "BLUE   = (255,178,50)\n",
    "YELLOW = (0,255,255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GJlJUh2YFTea"
   },
   "outputs": [],
   "source": [
    "def draw_label(im, label, x, y):\n",
    "    \"\"\"Draw text onto image at location.\"\"\"\n",
    "    # Get text size.\n",
    "    text_size = cv2.getTextSize(label, FONT_FACE, FONT_SCALE, THICKNESS)\n",
    "    dim, baseline = text_size[0], text_size[1]\n",
    "    # Use text size to create a BLACK rectangle.\n",
    "    cv2.rectangle(im, (x,y), (x + dim[0], y + dim[1] + baseline), (0,0,0), cv2.FILLED);\n",
    "    # Display text inside the rectangle.\n",
    "    cv2.putText(im, label, (x, y + dim[1]), FONT_FACE, FONT_SCALE, YELLOW, THICKNESS, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "63TgkG9ZFYFs"
   },
   "outputs": [],
   "source": [
    "def pre_process(input_image, net):\n",
    "      # Create a 4D blob from a frame.\n",
    "      blob = cv2.dnn.blobFromImage(input_image, 1/255,  (INPUT_WIDTH, INPUT_HEIGHT), [0,0,0], 1, crop=False)\n",
    "\n",
    "      # Sets the input to the network.\n",
    "      net.setInput(blob)\n",
    "\n",
    "      # Run the forward pass to get output of the output layers.\n",
    "      outputs = net.forward(net.getUnconnectedOutLayersNames())\n",
    "      return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "aQYVObLqNtNf"
   },
   "outputs": [],
   "source": [
    "def post_process(input_image, outputs):\n",
    "      # Lists to hold respective values while unwrapping.\n",
    "      class_ids = []\n",
    "      confidences = []\n",
    "      boxes = []\n",
    "      # Rows.\n",
    "      rows = outputs[0].shape[1]\n",
    "      image_height, image_width = input_image.shape[:2]\n",
    "      # Resizing factor.\n",
    "      x_factor = image_width / INPUT_WIDTH\n",
    "      y_factor =  image_height / INPUT_HEIGHT\n",
    "      # Iterate through detections.\n",
    "      for r in range(rows):\n",
    "            row = outputs[0][0][r]\n",
    "            confidence = row[4]\n",
    "            # Discard bad detections and continue.\n",
    "            if confidence >= CONFIDENCE_THRESHOLD:\n",
    "                  classes_scores = row[5:]\n",
    "                  # Get the index of max class score.\n",
    "                  class_id = np.argmax(classes_scores)\n",
    "                  #  Continue if the class score is above threshold.\n",
    "                  if (classes_scores[class_id] > SCORE_THRESHOLD):\n",
    "                        confidences.append(confidence)\n",
    "                        class_ids.append(class_id)\n",
    "                        cx, cy, w, h = row[0], row[1], row[2], row[3]\n",
    "                        left = int((cx - w/2) * x_factor)\n",
    "                        top = int((cy - h/2) * y_factor)\n",
    "                        width = int(w * x_factor)\n",
    "                        height = int(h * y_factor)\n",
    "                        box = np.array([left, top, width, height])\n",
    "                        boxes.append(box)\n",
    "      # Perform non maximum suppression to eliminate redundant, overlapping boxes with lower confidences.\n",
    "      indices = cv2.dnn.NMSBoxes(boxes, confidences, CONFIDENCE_THRESHOLD, NMS_THRESHOLD)\n",
    "      for i in indices:\n",
    "            box = boxes[i]\n",
    "            left = box[0]\n",
    "            top = box[1]\n",
    "            width = box[2]\n",
    "            height = box[3]             \n",
    "            # Draw bounding box.             \n",
    "            cv2.rectangle(input_image, (left, top), (left + width, top + height), BLUE, 3*THICKNESS)\n",
    "            # Class label.                      \n",
    "            label = \"{}:{:.2f}\".format(classes[class_ids[i]], confidences[i])             \n",
    "            # Draw label.             \n",
    "            draw_label(input_image, label, left, top)\n",
    "      return input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vnUBwnbAODBB"
   },
   "outputs": [],
   "source": [
    "def get_detection(image,model,class_file):\n",
    "  classesFile = class_file\n",
    "  classes = None\n",
    "  with open(classesFile, 'rt') as f:\n",
    "        classes = f.read().rstrip('\\n').split('\\n')\n",
    "  # Load image.\n",
    "  frame = cv2.imread(image)\n",
    "  # Give the weight files to the model and load the network using them.\n",
    "  modelWeights = model\n",
    "  net = cv2.dnn.readNet(modelWeights)\n",
    "  # Process image.\n",
    "  detections = pre_process(frame, net)\n",
    "  img = post_process(frame.copy(), detections)\n",
    "  \"\"\"\n",
    "  Put efficiency information. The function getPerfProfile returns the overall time for inference(t) \n",
    "  and the timings for each of the layers(in layersTimes).\n",
    "  \"\"\"\n",
    "  t, _ = net.getPerfProfile()\n",
    "  label = 'Inference time: %.2f ms' % (t * 1000.0 /  cv2.getTickFrequency())\n",
    "  print(label)\n",
    "  cv2.putText(img, label, (20, 40), FONT_FACE, FONT_SCALE,  (0, 0, 255), THICKNESS, cv2.LINE_AA)\n",
    "  return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGd9-qadDpMt"
   },
   "source": [
    "Card detection from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "WyUKkI7g5zqY",
    "outputId": "8d9b1de3-3b17-4c5a-a111-1531ddb5d7e3"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'classes1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mget_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample/input3.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/card.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclasses1.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_file1.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m,img)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(img)\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mget_detection\u001b[0;34m(image, model, class_file)\u001b[0m\n\u001b[1;32m      2\u001b[0m classesFile \u001b[38;5;241m=\u001b[39m class_file\n\u001b[1;32m      3\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclassesFile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m       classes \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load image.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'classes1.txt'"
     ]
    }
   ],
   "source": [
    "img = get_detection(\"sample/input3.png\",\"models/card.onnx\",\"classes1.txt\")\n",
    "cv2.imwrite(\"output_file1.jpg\",img)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1q7VSNVDy_7"
   },
   "source": [
    "Detecting card name from image ,wanted to do it on cropped image of card <br> but since time and data was limited couldnt get accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "HpLTt8plAXdj",
    "outputId": "fabf1dcb-35f3-47d9-e2b1-189dff867116"
   },
   "outputs": [],
   "source": [
    "img = get_detection(\"sample/input2.png\",\"models/no_of_card.onnx\",'classes.txt')\n",
    "cv2.imwrite(\"output_file2.jpg\",img)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "playing_card_detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
